{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b025b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def unpickle(fn):\n",
    "    with open(fn, 'rb') as fo:\n",
    "        data = np.load(fn, allow_pickle=True)\n",
    "    return data['x'], data['y']\n",
    "    #return x, y\n",
    "\n",
    "import sys, pathlib, random\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "import shutil\n",
    "\n",
    "pathlib.Path('data').mkdir(exist_ok=True)\n",
    "datadir_recycle = pathlib.Path('data/recycle')\n",
    "datadir_recycle_small = pathlib.Path('data/recycle-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9b4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_recycle_data(npz_filename):\n",
    "    #data from http://web.cecs.pdx.edu/~singh/rcyc-web/dataset.html\n",
    "    d = np.load(npz_filename, allow_pickle=True)\n",
    "    datadir = datadir_recycle\n",
    "    datadir_small = datadir_recycle_small\n",
    "\n",
    "    if datadir.exists() and datadir_small.exists():\n",
    "        print(f'{datadir} and {datadir_small} already exist, skipping download of recycle dataset')\n",
    "        return\n",
    "    \n",
    "    if datadir.exists(): shutil.rmtree(datadir)\n",
    "    if datadir_small.exists(): shutil.rmtree(datadir_small)\n",
    "    \n",
    "    labels = ['boxes', 'glass_bottles', 'soda_cans', 'crushed_soda_cans', 'water_bottles']\n",
    "   \n",
    "    datadir.mkdir(exist_ok=True)\n",
    "    datadir_small.mkdir(exist_ok=True)\n",
    "    for dirn in ['train', 'val', 'test']:\n",
    "        (datadir / dirn).mkdir(exist_ok=True)\n",
    "        (datadir_small / dirn).mkdir(exist_ok=True)\n",
    "        for label in labels:\n",
    "            (datadir/ dirn / str(label)).mkdir(exist_ok=True)\n",
    "            (datadir_small / dirn / str(label)).mkdir(exist_ok=True)\n",
    "\n",
    "    print(d.files)\n",
    "    print('splitting training set')\n",
    "    for i,x in enumerate(d['x_train']):\n",
    "        dirn = 'train' if random.random() > 0.2 else 'val'\n",
    "        y = d['y_train'][i][0]\n",
    "        if i%100 == 0: print(i,y, label, dirn)\n",
    "\n",
    "        label = labels[y]\n",
    "        img = Image.fromarray(x)\n",
    "        img.save(datadir / dirn / label / f'{i}.jpg')\n",
    "        if random.random() < 0.22:\n",
    "            img.save(datadir_small / dirn / label / f'{i}.jpg')\n",
    "\n",
    "    print('saving test set')\n",
    "    for i,x in enumerate(d['x_test']):\n",
    "        dirn = 'test'\n",
    "        y = d['y_test'][i][0]\n",
    "        if i%100 == 0: print(i,y, label, dirn)\n",
    "\n",
    "        label = labels[y]\n",
    "        img = Image.fromarray(x)\n",
    "        img.save(datadir / dirn / label / f'{i}.jpg')\n",
    "\n",
    "        if random.random() < 0.22:\n",
    "            img.save(datadir_small / dirn / label / f'{i}.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8536f91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/recycle and data/recycle-small already exist, skipping download of recycle dataset\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "url = 'http://web.cecs.pdx.edu/~singh/rcyc-web/recycle_data_shuffled.tar.gz'\n",
    "tarballfn = pathlib.Path('data/recycle_data_shuffled.tar.gz')\n",
    "npzfn = pathlib.Path('data/recycle_data_shuffled.npz')\n",
    "\n",
    "if datadir_recycle.exists() and datadir_recycle_small.exists():\n",
    "    print(f'{datadir_recycle} and {datadir_recycle_small} already exist, skipping download of recycle dataset')\n",
    "else:\n",
    "    if not npzfn.exists():\n",
    "        if not tarballfn.exists():\n",
    "            print(f'downloading {url}....')\n",
    "            urllib.request.urlretrieve(url, tarballfn)\n",
    "            print('done')\n",
    "        else:\n",
    "            print(f'{tarballfn} exists, skipping download')\n",
    "\n",
    "        print(f'extracting data from {tarballfn}')\n",
    "        tar = tarfile.open(tarballfn, \"r:gz\")\n",
    "        tar.extractall(path='data')\n",
    "        tar.close()\n",
    "        split_recycle_data(npzfn)\n",
    "    else:\n",
    "        print(f'{npzfn} exists, skipping tarball download')\n",
    "\n",
    "if tarballfn.exists():\n",
    "    print(f'cleaning up {tarballfn}')\n",
    "    tarballfn.unlink()\n",
    "\n",
    "if npzfn.exists():\n",
    "    print(f'cleaning up {npzfn}')\n",
    "    npzfn.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08b776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets --upgrade --quiet\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cb8f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/garbage exists, skipping download and prep of garbage dataset\n"
     ]
    }
   ],
   "source": [
    "origdir = pathlib.Path('./garbage-classification/Garbage classification/Garbage classification')\n",
    "targetdir = pathlib.Path('data/garbage')\n",
    "\n",
    "if targetdir.exists():\n",
    "    print(f'{targetdir} exists, skipping download and prep of garbage dataset')\n",
    "else:\n",
    "    od.download('https://www.kaggle.com/asdasdasasdas/garbage-classification')\n",
    "\n",
    "    targetdir.mkdir()\n",
    "\n",
    "    for setn in ['train','test', 'val']:\n",
    "       (targetdir / setn).mkdir()\n",
    "    #20% for test\n",
    "    #then 20% of the remaining for val\n",
    "\n",
    "    for dirn in origdir.iterdir():\n",
    "        print(f'doing {dirn}')\n",
    "\n",
    "        for setn in ['train','test', 'val']:\n",
    "            (targetdir / setn / dirn.name).mkdir()\n",
    "        for fn in dirn.iterdir():\n",
    "            rnd = random.random()\n",
    "            if rnd < 0.2:\n",
    "                #move it to test\n",
    "                setn = 'test'\n",
    "            elif rnd < 0.36: # 20% of 80%\n",
    "                #move it to val\n",
    "                setn = 'val'\n",
    "            else:\n",
    "                #move it to test\n",
    "                setn = 'train'\n",
    "            fn.rename(targetdir / setn / dirn.name / fn.name)\n",
    "\n",
    "    shutil.rmtree('./garbage-classification')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ca9269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/inception-garbage-7.model\n",
      "histories/inception-garbage-7.history\n",
      "models/inception-recycle-7.model\n",
      "histories/inception-recycle-7.history\n",
      "models/inception-recycle-small-7.model\n",
      "histories/inception-recycle-small-7.history\n",
      "models/resnet-garbage-3.model\n",
      "histories/resnet-garbage-3.history\n",
      "models/resnet-recycle-3.model\n",
      "histories/resnet-recycle-3.history\n",
      "models/resnet-recycle-small-3.model\n",
      "histories/resnet-recycle-small-3.history\n"
     ]
    }
   ],
   "source": [
    "#now download the pre-trained models and histories\n",
    "pathlib.Path('models').mkdir(exist_ok=True)\n",
    "pathlib.Path('histories').mkdir(exist_ok=True)\n",
    "for filest in ['inception-garbage-7', 'inception-recycle-7', 'inception-recycle-small-7', 'resnet-garbage-3', 'resnet-recycle-3', 'resnet-recycle-small-3']:\n",
    "    for filep in [pathlib.Path(f'models/{filest}.model'), pathlib.Path(f'histories/{filest}.history')]:\n",
    "        print(filep)\n",
    "    \n",
    "        if not filep.exists():\n",
    "            urllib.request.urlretrieve(f'https://recycle-classifier-models.s3.eu-west-2.amazonaws.com/{filep}', filep)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfff94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
